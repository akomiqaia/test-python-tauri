"PDFFigures 2.0: Mining Figures from Research Papers\nChristopher Clark Santosh Divvala\nAllen Institute for Artificial Intelligence\nUniversity of Washington\n{chrisc, santoshd}@allenai.org\nhttp://pdffigures2.allenai.org\nABSTRACT\nFigures and tables are key sources of information in many\nscholarly documents. However, current academic search en-\ngines do not make use of figures and tables when semanti-\ncally parsing documents or presenting document summaries\nto users. To facilitate these applications we develop an algo-\nrithm that extracts figures, tables, and captions from docu-\nments called “PDFFigures 2.0.” Our proposed approach ana-\nlyzes the structure of individual pages by detecting captions,\ngraphical elements, and chunks of body text, and then lo-\ncates figures and tables by reasoning about the empty re-\ngions within that text. To evaluate our work, we intro-\nduce a new dataset of computer science papers, along with\nground truth labels for the locations of the figures, tables,\nand captions within them. Our algorithm achieves impres-\nsive results (94% precision at 90% recall) on this dataset\nsurpassing previous state of the art. Further, we show how\nour framework was used to extract figures from a corpus of\nover one million papers, and how the resulting extractions\nwere integrated into the user interface of a smart academic\nsearch engine, Semantic Scholar (www.semanticscholar.org).\nFinally, we present results of exploratory data analysis com-\npleted on the extracted figures as well as an extension of our\nmethod for the task of section title extraction. We release\nour dataset and code on our project webpage for enabling\nfuture research (http://pdffigures2.allenai.org).\nKeywords\nScalable figure extraction; academic search engine; section\ntitle extraction; figure usage analysis\n1. INTRODUCTION\nTraditional tools for organizing and presenting digital li-\nbraries only make use of the text of the documents they in-\ndex. Focusing exclusively on text, however, comes at a price\nbecause in many domains much of the important content is\ncontained within figures and tables. Especially in scholarly\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full cita-\ntion on the first page. Copyrights for components of this work owned by others than\nACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-\npublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nJCDL ’16, June 19-23, 2016, Newark, NJ, USA\nc© 2016 ACM. ISBN 978-1-4503-4229-2/16/06. . . $15.00\nDOI: http://dx.doi.org/10.1145/2910896.2910904\ndomains, authors frequently use figures and tables to com-\npare their work to previous work, to convey the quantitative\nresults of their experiments, or to provide graphics that help\nreaders understand their methods. Therefore parsing figures\nand tables is a necessary component of any system that seeks\nto gain a semantic understanding of such documents.\nTables and figures also have the potential to be used as\npowerful document summarization tools. It is common to\nget the gist of a paper by glancing through the figures1,\nwhich often contain both the main results as well as visual\naids that outline the work being discussed. Being able to\nextract these figures and present them to a user would be\nan effective way to let users quickly get an overview of the\npaper’s content. To this end, we introduce PDFFigures 2.0.\nPDFFigures 2.0 takes as input computer science papers in\nPDF format and outputs the figures, tables, and captions\ncontained within them.\nOur work builds upon the PDFFigures algorithm [5]. The\napproach used by [5] has high accuracy but was only tested\non papers from a narrow range of sources. In this work,\nwe improve upon that method to build a figure extractor\nthat is suitable for use as part of academic search engines\nfor computer science papers. To meet this goal we improve\nupon the accuracy of PDFFigures [5] and, more importantly,\nbuild an extractor that is effective across the entire range of\ncontent in a digital library. This requires an approach that\nis robust to the large number of possible formats and styles\npapers might use. Particular challenges include handling\ndocuments with widely differing spacing conventions, avoid-\ning false positives while maintaining the ability to extract\na broad range of possible captions, and extracting a highly\nvaried selection of figures and tables.\nOur approach follows the same general structure used\nin [5] (see Section 3) and employs data-driven heuristics\nthat leverage formatting conventions used consistently in\nthe computer science domain. Following a heuristic ap-\nproach makes our method transparent and easy to mod-\nify [13], which we have found to be important for developing\nan effective solution to this task.\nWhile our focus is on extracting figures, our method also\nproduces a rich decomposition of the document and anal-\nysis of the text. In this paper we demonstrate how this\nanalysis can be leveraged for other extraction tasks, such as\nidentifying section titles. Section titles are important be-\ncause they reveal the overall structure of the document, and\ncan be a crucial feature for upstream components analyzing\n1Throughout this paper we use the term “figures” to refer to\nboth tables and figures along with their associated captions"